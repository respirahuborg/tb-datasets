{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RespiraHub — Trial 2: Fixed Segmentation\n",
    "\n",
    "**Perubahan dari Trial 1:**\n",
    "1. Segmentasi: pad per-file ke 3s (bukan concatenate+split)\n",
    "2. Hyfe filter: >= 0.5 (bukan 0.8)\n",
    "3. Sisanya sama (Wav2Vec2-base, 10-fold CV, same hyperparams)\n",
    "\n",
    "**Target:** AUROC >= 0.80 (ideally >= 0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Wav2Vec2Model\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device('mps')\n",
    "    print('Using Apple Silicon MPS')\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "    print('Using CUDA')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    print('Using CPU')\n",
    "\n",
    "print(f'PyTorch {torch.__version__}, Device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 2: Load & Merge Metadata (Hyfe filter 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_DIR = '/Users/aida/code/development/tb-datasets/data/solicited/'\n",
    "CLINICAL_PATH = '/Users/aida/code/development/tb-datasets/data/metadata/CODA_TB_Clinical_Meta_Info.csv'\n",
    "ADDITIONAL_PATH = '/Users/aida/code/development/tb-datasets/data/metadata/CODA_TB_additional_variables_train.csv'\n",
    "SOLICITED_PATH = '/Users/aida/code/development/tb-datasets/data/metadata/CODA_TB_Solicited_Meta_Info.csv'\n",
    "\n",
    "clinical = pd.read_csv(CLINICAL_PATH)\n",
    "additional = pd.read_csv(ADDITIONAL_PATH)\n",
    "solicited = pd.read_csv(SOLICITED_PATH)\n",
    "\n",
    "meta = clinical.merge(additional, on='participant', how='left')\n",
    "meta['label'] = (meta['tb_status'] == 'positive').astype(int)\n",
    "\n",
    "print(f'Participants: {len(meta)}')\n",
    "print(f'TB+: {meta[\"label\"].sum()}, TB-: {(meta[\"label\"] == 0).sum()}')\n",
    "print(f'Prevalence: {meta[\"label\"].mean():.1%}')\n",
    "\n",
    "df = solicited.merge(meta, on='participant', how='left')\n",
    "\n",
    "# === CHANGE: Hyfe filter 0.5 instead of 0.8 ===\n",
    "print(f'\\nTotal cough files: {len(df)}')\n",
    "print(f'Trial 1 (>=0.8): {len(df[df[\"sound_prediction_score\"] >= 0.8])}')\n",
    "df = df[df['sound_prediction_score'] >= 0.5].reset_index(drop=True)\n",
    "print(f'Trial 2 (>=0.5): {len(df)}')\n",
    "\n",
    "df['filepath'] = df['filename'].apply(lambda f: os.path.join(AUDIO_DIR, f))\n",
    "df['file_exists'] = df['filepath'].apply(os.path.exists)\n",
    "df = df[df['file_exists']].reset_index(drop=True)\n",
    "\n",
    "print(f'\\nFinal: {len(df)} cough files from {df[\"participant\"].nunique()} participants')\n",
    "\n",
    "# coughs per patient\n",
    "coughs_per_pt = df.groupby('participant').size()\n",
    "print(f'\\nCoughs per patient:')\n",
    "print(f'  Min: {coughs_per_pt.min()}, Max: {coughs_per_pt.max()}')\n",
    "print(f'  Mean: {coughs_per_pt.mean():.1f}, Median: {coughs_per_pt.median():.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 3: New Segmentation — Pad Per-File\n",
    "\n",
    "**Trial 1 (SALAH):** concatenate semua cough > split 3s > banyak zero padding, 58% patient cuma 1 segment\n",
    "\n",
    "**Trial 2 (FIX):** setiap file cough individual di-pad ke 3s = 1 segment per file. Patient dengan 8 files > 8 segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SR = 16000\n",
    "SEGMENT_SEC = 3.0\n",
    "SEGMENT_SAMPLES = int(TARGET_SR * SEGMENT_SEC)  # 48000\n",
    "\n",
    "def load_and_pad(filepath, target_sr=16000, segment_samples=48000):\n",
    "    \"\"\"Load single cough file, resample to 16kHz, center-pad to 3s.\"\"\"\n",
    "    try:\n",
    "        w, sr = torchaudio.load(filepath)\n",
    "        if w.shape[0] > 1:\n",
    "            w = w.mean(dim=0, keepdim=True)\n",
    "        if sr != target_sr:\n",
    "            w = torchaudio.transforms.Resample(sr, target_sr)(w)\n",
    "        w = w.squeeze(0)\n",
    "        \n",
    "        if len(w) < segment_samples:\n",
    "            pad_total = segment_samples - len(w)\n",
    "            pad_left = pad_total // 2\n",
    "            pad_right = pad_total - pad_left\n",
    "            w = torch.nn.functional.pad(w, (pad_left, pad_right))\n",
    "        elif len(w) > segment_samples:\n",
    "            start = (len(w) - segment_samples) // 2\n",
    "            w = w[start:start + segment_samples]\n",
    "        \n",
    "        return w\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "print(f'Target: {TARGET_SR}Hz, {SEGMENT_SEC}s = {SEGMENT_SAMPLES} samples')\n",
    "print(f'Strategy: pad each file individually (center-padded)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Build segments: 1 file = 1 segment ===\n",
    "all_segments = []\n",
    "all_labels = []\n",
    "all_pids = []\n",
    "skipped = 0\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc='Loading audio'):\n",
    "    seg = load_and_pad(row['filepath'], TARGET_SR, SEGMENT_SAMPLES)\n",
    "    if seg is not None:\n",
    "        all_segments.append(seg)\n",
    "        all_labels.append(row['label'])\n",
    "        all_pids.append(row['participant'])\n",
    "    else:\n",
    "        skipped += 1\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_pids = np.array(all_pids)\n",
    "\n",
    "print(f'\\nTotal segments: {len(all_segments)}')\n",
    "print(f'Skipped: {skipped}')\n",
    "print(f'Unique participants: {len(np.unique(all_pids))}')\n",
    "\n",
    "# === Compare with Trial 1 ===\n",
    "pid_counts = Counter(all_pids)\n",
    "counts = list(pid_counts.values())\n",
    "print(f'\\nSegments per patient (Trial 2):')\n",
    "print(f'  Min: {min(counts)}, Max: {max(counts)}')\n",
    "print(f'  Mean: {np.mean(counts):.1f}, Median: {np.median(counts):.1f}')\n",
    "print(f'  1 segment only: {sum(1 for c in counts if c == 1)}')\n",
    "print(f'  >=3 segments: {sum(1 for c in counts if c >= 3)}')\n",
    "print(f'  >=5 segments: {sum(1 for c in counts if c >= 5)}')\n",
    "print(f'\\n--- Trial 1 was: 1818 segments, mean 1.7/patient, 626 with only 1 ---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 4: Audio Content Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ratios = []\n",
    "for seg in all_segments[:500]:\n",
    "    nonzero = (seg.abs() > 1e-6).sum().item()\n",
    "    audio_ratios.append(nonzero / len(seg))\n",
    "\n",
    "print(f'Audio content ratio (sample of 500):')\n",
    "print(f'  Mean: {np.mean(audio_ratios):.1%}')\n",
    "print(f'  Min: {np.min(audio_ratios):.1%}')\n",
    "print(f'  Max: {np.max(audio_ratios):.1%}')\n",
    "print(f'  <10% audio: {sum(1 for r in audio_ratios if r < 0.1)}')\n",
    "print(f'  <20% audio: {sum(1 for r in audio_ratios if r < 0.2)}')\n",
    "print(f'\\nNote: ~17% audio content expected (0.5s cough in 3s segment)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 5: Model + Dataset + Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoughClassifier(nn.Module):\n",
    "    def __init__(self, model_name='facebook/wav2vec2-base', dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.wav2vec2 = Wav2Vec2Model.from_pretrained(model_name)\n",
    "        self.wav2vec2.feature_extractor._freeze_parameters()\n",
    "        hidden = self.wav2vec2.config.hidden_size\n",
    "        self.head = nn.Sequential(nn.Dropout(dropout), nn.Linear(hidden, 1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.wav2vec2(x).last_hidden_state\n",
    "        pooled = out.mean(dim=1)\n",
    "        return self.head(pooled).squeeze(-1)\n",
    "\n",
    "class CoughDataset(Dataset):\n",
    "    def __init__(self, segments, labels, pids):\n",
    "        self.segments = segments\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "        self.pids = pids\n",
    "    def __len__(self): return len(self.segments)\n",
    "    def __getitem__(self, idx):\n",
    "        return {'audio': self.segments[idx], 'label': self.labels[idx], 'pid': self.pids[idx]}\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "LR = 3e-5\n",
    "EPOCHS = 5\n",
    "GRAD_ACCUM = 8\n",
    "WARMUP_RATIO = 0.1\n",
    "N_FOLDS = 10\n",
    "\n",
    "print(f'Batch: {BATCH_SIZE} (effective: {BATCH_SIZE * GRAD_ACCUM})')\n",
    "print(f'Epochs: {EPOCHS}, LR: {LR}, Folds: {N_FOLDS}')\n",
    "\n",
    "print('\\nLoading Wav2Vec2-base...')\n",
    "m = CoughClassifier()\n",
    "n_train = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "print(f'Trainable params: {n_train/1e6:.1f}M')\n",
    "dummy = torch.randn(2, SEGMENT_SAMPLES)\n",
    "with torch.no_grad(): out = m(dummy)\n",
    "print(f'Forward pass OK: {out.shape}')\n",
    "del m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 6: Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_fold(fold_num, train_segs, train_labs, train_pids,\n",
    "                   val_segs, val_labs, val_pids):\n",
    "    train_ds = CoughDataset(train_segs, train_labs, train_pids)\n",
    "    val_ds = CoughDataset(val_segs, val_labs, val_pids)\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    \n",
    "    model = CoughClassifier().to(DEVICE)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()), lr=LR, weight_decay=0.01\n",
    "    )\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    total_steps = (len(train_loader) * EPOCHS) // GRAD_ACCUM\n",
    "    warmup_steps = int(total_steps * WARMUP_RATIO)\n",
    "    scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "        optimizer, start_factor=0.1, total_iters=max(warmup_steps, 1)\n",
    "    )\n",
    "    \n",
    "    best_auroc = 0\n",
    "    best_patient_logits = {}\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        for step, batch in enumerate(train_loader):\n",
    "            audio = batch['audio'].to(DEVICE)\n",
    "            labels = batch['label'].to(DEVICE)\n",
    "            loss = criterion(model(audio), labels) / GRAD_ACCUM\n",
    "            loss.backward()\n",
    "            \n",
    "            if (step + 1) % GRAD_ACCUM == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step(); scheduler.step(); optimizer.zero_grad()\n",
    "            train_loss += loss.item() * GRAD_ACCUM\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        seg_probs, seg_labels, seg_pids = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                audio = batch['audio'].to(DEVICE)\n",
    "                probs = torch.sigmoid(model(audio)).cpu().numpy()\n",
    "                seg_probs.extend(probs)\n",
    "                seg_labels.extend(batch['label'].numpy())\n",
    "                seg_pids.extend(batch['pid'])\n",
    "        \n",
    "        pt_p, pt_l = {}, {}\n",
    "        for pid, prob, lab in zip(seg_pids, seg_probs, seg_labels):\n",
    "            pt_p.setdefault(pid, []).append(prob)\n",
    "            pt_l[pid] = lab\n",
    "        \n",
    "        yt = np.array([pt_l[p] for p in pt_p])\n",
    "        yp = np.array([np.mean(v) for v in pt_p.values()])\n",
    "        auroc = roc_auc_score(yt, yp) if len(np.unique(yt)) > 1 else 0.5\n",
    "        \n",
    "        print(f'  Epoch {epoch+1}/{EPOCHS} — loss: {train_loss:.4f}, AUROC: {auroc:.4f}')\n",
    "        \n",
    "        if auroc > best_auroc:\n",
    "            best_auroc = auroc\n",
    "            best_patient_logits = {pid: np.mean(v) for pid, v in pt_p.items()}\n",
    "            os.makedirs('checkpoints_t2', exist_ok=True)\n",
    "            torch.save(model.state_dict(), f'checkpoints_t2/wav2vec2_fold{fold_num}.pt')\n",
    "    \n",
    "    del model, optimizer\n",
    "    if DEVICE.type == 'mps': torch.mps.empty_cache()\n",
    "    elif DEVICE.type == 'cuda': torch.cuda.empty_cache()\n",
    "    \n",
    "    return best_auroc, best_patient_logits\n",
    "\n",
    "print('Training function ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 7: Run 10-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pids = np.unique(all_pids)\n",
    "pid_labels = np.array([all_labels[all_pids == pid][0] for pid in unique_pids])\n",
    "\n",
    "n_folds_actual = min(N_FOLDS, int(min(Counter(pid_labels).values()) * 0.8))\n",
    "skf = StratifiedKFold(n_splits=n_folds_actual, shuffle=True, random_state=42)\n",
    "\n",
    "fold_aurocs = []\n",
    "all_patient_logits = {}\n",
    "all_patient_labels = {}\n",
    "\n",
    "print(f'=== TRIAL 2: Fixed Segmentation ===')\n",
    "print(f'Segments: {len(all_segments)} (Trial 1: 1818)')\n",
    "print(f'Patients: {len(unique_pids)}')\n",
    "print(f'Folds: {n_folds_actual}')\n",
    "print(f'Device: {DEVICE}')\n",
    "print(f'\\nStarting training...\\n')\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(unique_pids, pid_labels)):\n",
    "    print(f'=== Fold {fold+1}/{n_folds_actual} ===')\n",
    "    \n",
    "    train_pids_set = set(unique_pids[train_idx])\n",
    "    val_pids_set = set(unique_pids[val_idx])\n",
    "    \n",
    "    tr_s, tr_l, tr_p = [], [], []\n",
    "    va_s, va_l, va_p = [], [], []\n",
    "    \n",
    "    for seg, lab, pid in zip(all_segments, all_labels, all_pids):\n",
    "        if pid in train_pids_set:\n",
    "            tr_s.append(seg); tr_l.append(lab); tr_p.append(pid)\n",
    "        else:\n",
    "            va_s.append(seg); va_l.append(lab); va_p.append(pid)\n",
    "    \n",
    "    print(f'  Train: {len(tr_s)} segments ({len(train_pids_set)} patients)')\n",
    "    print(f'  Val:   {len(va_s)} segments ({len(val_pids_set)} patients)')\n",
    "    \n",
    "    auroc, patient_logits = train_one_fold(\n",
    "        fold+1, tr_s, tr_l, tr_p, va_s, va_l, va_p\n",
    "    )\n",
    "    \n",
    "    fold_aurocs.append(auroc)\n",
    "    all_patient_logits.update(patient_logits)\n",
    "    for pid in val_pids_set:\n",
    "        all_patient_labels[pid] = pid_labels[unique_pids == pid][0]\n",
    "    \n",
    "    print(f'  ✅ Fold {fold+1} best AUROC: {auroc:.4f}\\n')\n",
    "\n",
    "print('=' * 50)\n",
    "print(f'TRIAL 2 RESULT')\n",
    "print(f'Mean AUROC: {np.mean(fold_aurocs):.4f} +/- {np.std(fold_aurocs):.4f}')\n",
    "print(f'Per-fold: {[f\"{a:.3f}\" for a in fold_aurocs]}')\n",
    "print(f'\\n--- Comparison ---')\n",
    "print(f'Trial 1: 0.7330 +/- 0.0565')\n",
    "print(f'Trial 2: {np.mean(fold_aurocs):.4f} +/- {np.std(fold_aurocs):.4f}')\n",
    "print(f'Zambia:  0.852')\n",
    "print(f'Delta:   {np.mean(fold_aurocs) - 0.7330:+.4f} vs Trial 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 8: Results — ROC + Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pids_order = sorted(all_patient_logits.keys())\n",
    "y_true = np.array([all_patient_labels[p] for p in pids_order])\n",
    "y_prob = np.array([all_patient_logits[p] for p in pids_order])\n",
    "\n",
    "fpr_t2, tpr_t2, _ = roc_curve(y_true, y_prob)\n",
    "auroc_t2 = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "plt.figure(figsize=(8, 7))\n",
    "plt.plot(fpr_t2, tpr_t2, 'r-', lw=2.5, label=f'Trial 2 ({auroc_t2:.3f})')\n",
    "plt.plot([0,1],[0,1],'k--', alpha=0.2)\n",
    "plt.axhspan(0.90, 1.0, xmin=0, xmax=0.30, alpha=0.08, color='green', label='WHO TPP zone')\n",
    "plt.axhline(0.90, color='r', ls=':', alpha=0.3)\n",
    "plt.axvline(0.30, color='g', ls=':', alpha=0.3)\n",
    "plt.xlabel('FPR (1 - Specificity)', fontsize=12)\n",
    "plt.ylabel('TPR (Sensitivity)', fontsize=12)\n",
    "plt.title('RespiraHub Trial 2 — Fixed Segmentation', fontsize=14)\n",
    "plt.legend(fontsize=11); plt.grid(alpha=0.15)\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_trial2.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{\"Thresh\":>7} {\"Sens\":>7} {\"Spec\":>7} {\"PPV\":>7} {\"NPV\":>7}')\n",
    "print('-' * 40)\n",
    "\n",
    "best_t, best_j = 0.5, -1\n",
    "who_met = False\n",
    "\n",
    "for t in np.arange(0.15, 0.85, 0.05):\n",
    "    pred = (y_prob >= t).astype(int)\n",
    "    tp = np.sum((pred == 1) & (y_true == 1))\n",
    "    tn = np.sum((pred == 0) & (y_true == 0))\n",
    "    fp = np.sum((pred == 1) & (y_true == 0))\n",
    "    fn = np.sum((pred == 0) & (y_true == 1))\n",
    "    sens = tp/(tp+fn) if (tp+fn) else 0\n",
    "    spec = tn/(tn+fp) if (tn+fp) else 0\n",
    "    ppv = tp/(tp+fp) if (tp+fp) else 0\n",
    "    npv = tn/(tn+fn) if (tn+fn) else 0\n",
    "    \n",
    "    flag = ' ✅ WHO' if (sens >= 0.90 and spec >= 0.70) else ''\n",
    "    if sens >= 0.90 and spec >= 0.70: who_met = True\n",
    "    \n",
    "    j = sens + spec - 1\n",
    "    if j > best_j: best_j, best_t = j, t\n",
    "    \n",
    "    print(f'{t:>7.2f} {sens:>7.3f} {spec:>7.3f} {ppv:>7.3f} {npv:>7.3f}{flag}')\n",
    "\n",
    "print(f'\\nBest Youden threshold: {best_t:.2f}')\n",
    "if who_met:\n",
    "    print('✅ WHO TPP achievable!')\n",
    "else:\n",
    "    print('⚠️ WHO TPP not met. Phase 2 (+ anamnesis/domain adapt) should help.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 9: Adversarial Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fold = np.argmax(fold_aurocs) + 1\n",
    "model = CoughClassifier().to(DEVICE)\n",
    "model.load_state_dict(torch.load(f'checkpoints_t2/wav2vec2_fold{best_fold}.pt', map_location=DEVICE))\n",
    "model.eval()\n",
    "print(f'Loaded fold {best_fold} (AUROC={fold_aurocs[best_fold-1]:.4f})')\n",
    "\n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(20, SEGMENT_SAMPLES).to(DEVICE)\n",
    "    p_noise = torch.sigmoid(model(noise)).cpu().numpy()\n",
    "    print(f'White noise  -> P(TB+) = {p_noise.mean():.4f} +/- {p_noise.std():.4f}')\n",
    "    \n",
    "    silence = torch.zeros(20, SEGMENT_SAMPLES).to(DEVICE)\n",
    "    p_silence = torch.sigmoid(model(silence)).cpu().numpy()\n",
    "    print(f'Silence      -> P(TB+) = {p_silence.mean():.4f} +/- {p_silence.std():.4f}')\n",
    "    \n",
    "    t = torch.linspace(0, SEGMENT_SEC, SEGMENT_SAMPLES)\n",
    "    hum = (torch.sin(2*3.14159*50*t)*0.01).unsqueeze(0).repeat(20,1).to(DEVICE)\n",
    "    p_hum = torch.sigmoid(model(hum)).cpu().numpy()\n",
    "    print(f'50Hz hum     -> P(TB+) = {p_hum.mean():.4f} +/- {p_hum.std():.4f}')\n",
    "\n",
    "print('\\nAll should be ~0.50. If >> 0.60, model overfitting to background.')\n",
    "del model\n",
    "if DEVICE.type == 'mps': torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 10: Save Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'participant': pids_order,\n",
    "    'true_label': y_true,\n",
    "    'predicted_prob': y_prob,\n",
    "})\n",
    "results_df.to_csv('patient_predictions_trial2.csv', index=False)\n",
    "\n",
    "summary = {\n",
    "    'trial': 2,\n",
    "    'changes': ['per-file padding (not concatenate+split)', 'Hyfe filter >= 0.5 (was 0.8)'],\n",
    "    'model': 'Wav2Vec2-base (cough-only)',\n",
    "    'dataset': 'CODA TB solicited',\n",
    "    'n_participants': len(pids_order),\n",
    "    'n_segments': len(all_segments),\n",
    "    'segments_per_patient_mean': round(float(np.mean(counts)), 1),\n",
    "    'segment_sec': SEGMENT_SEC,\n",
    "    'hyfe_threshold': 0.5,\n",
    "    'n_folds': n_folds_actual,\n",
    "    'auroc_mean': round(float(np.mean(fold_aurocs)), 4),\n",
    "    'auroc_std': round(float(np.std(fold_aurocs)), 4),\n",
    "    'auroc_per_fold': [round(float(a), 4) for a in fold_aurocs],\n",
    "    'best_threshold': round(float(best_t), 2),\n",
    "    'trial1_auroc': 0.7330,\n",
    "    'zambia_auroc': 0.852,\n",
    "    'device': str(DEVICE),\n",
    "}\n",
    "with open('training_summary_trial2.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print('Saved:')\n",
    "print('  patient_predictions_trial2.csv')\n",
    "print('  training_summary_trial2.json')\n",
    "print('  checkpoints_t2/wav2vec2_fold*.pt')\n",
    "print('  roc_trial2.png')\n",
    "print()\n",
    "print('=' * 50)\n",
    "print('TRIAL 2 COMPLETE')\n",
    "print('=' * 50)\n",
    "print(f'Trial 1: 0.7330 +/- 0.0565')\n",
    "print(f'Trial 2: {np.mean(fold_aurocs):.4f} +/- {np.std(fold_aurocs):.4f}')\n",
    "print(f'Delta:   {np.mean(fold_aurocs) - 0.7330:+.4f}')\n",
    "print(f'Zambia:  0.852')\n",
    "print(f'\\nNext: if AUROC >= 0.80 -> validate on longitudinal data')\n",
    "print(f'       if AUROC < 0.80 -> add audio augmentation (Trial 3)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
