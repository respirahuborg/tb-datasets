{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RespiraHub — Trial 1 (Reproduction)\n",
    "\n",
    "**Goal:** Reproduce AUROC ~0.733 from original Trial 1.\n",
    "\n",
    "**Config (exact match):**\n",
    "- Model: Wav2Vec2-base, feature_extractor frozen, transformer trainable\n",
    "- Head: Dropout(0.5) → Linear(768, 1)\n",
    "- Segmentation: Concatenate all coughs per patient + split 3s\n",
    "- 10-fold stratified CV, patient-level split\n",
    "- Batch 4, effective batch 32 (grad accum 8), LR 3e-5, 5 epochs\n",
    "- All seeds fixed to 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Wav2Vec2Model\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === FIXED SEEDS EVERYWHERE ===\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "# MPS deterministic\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "print(f'PyTorch {torch.__version__}, Device: {DEVICE}')\n",
    "print(f'Seed: {SEED}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 2: Load Data + Segmentation (3s, concatenate all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_DIR = '/Users/aida/code/development/tb-datasets/data/solicited/'\n",
    "CLINICAL_PATH = '/Users/aida/code/development/tb-datasets/data/metadata/CODA_TB_Clinical_Meta_Info.csv'\n",
    "ADDITIONAL_PATH = '/Users/aida/code/development/tb-datasets/data/metadata/CODA_TB_additional_variables_train.csv'\n",
    "SOLICITED_PATH = '/Users/aida/code/development/tb-datasets/data/metadata/CODA_TB_Solicited_Meta_Info.csv'\n",
    "\n",
    "clinical = pd.read_csv(CLINICAL_PATH)\n",
    "additional = pd.read_csv(ADDITIONAL_PATH)\n",
    "solicited = pd.read_csv(SOLICITED_PATH)\n",
    "\n",
    "meta = clinical.merge(additional, on='participant', how='left')\n",
    "meta['label'] = meta['tb_status'].astype(int)\n",
    "\n",
    "df = solicited.merge(meta, on='participant', how='left')\n",
    "df['filepath'] = df['filename'].apply(lambda f: os.path.join(AUDIO_DIR, f))\n",
    "df['file_exists'] = df['filepath'].apply(os.path.exists)\n",
    "df = df[df['file_exists']].reset_index(drop=True)\n",
    "\n",
    "print(f'Participants: {meta[\"label\"].count()}, TB+: {meta[\"label\"].sum()}')\n",
    "print(f'Cough files: {len(df)} from {df[\"participant\"].nunique()} participants')\n",
    "\n",
    "# === Segmentation: concatenate all + split 3s ===\n",
    "TARGET_SR = 16000\n",
    "SEGMENT_SEC = 3.0\n",
    "SEGMENT_SAMPLES = int(TARGET_SR * SEGMENT_SEC)  # 48000\n",
    "GAP_SAMPLES = int(TARGET_SR * 0.05)  # 50ms gap\n",
    "\n",
    "def load_audio(filepath, target_sr=16000):\n",
    "    try:\n",
    "        w, sr = torchaudio.load(filepath)\n",
    "        if w.shape[0] > 1:\n",
    "            w = w.mean(dim=0, keepdim=True)\n",
    "        if sr != target_sr:\n",
    "            w = torchaudio.transforms.Resample(sr, target_sr)(w)\n",
    "        return w.squeeze(0)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "grouped = df.groupby('participant').agg(\n",
    "    label=('label', 'first'),\n",
    "    filepaths=('filepath', list),\n",
    ").reset_index()\n",
    "\n",
    "all_segments = []\n",
    "all_labels = []\n",
    "all_pids = []\n",
    "\n",
    "for _, row in tqdm(grouped.iterrows(), total=len(grouped), desc='Building 3s segments'):\n",
    "    pid = row['participant']\n",
    "    label = row['label']\n",
    "    waveforms = []\n",
    "    for fp in row['filepaths']:\n",
    "        w = load_audio(fp, TARGET_SR)\n",
    "        if w is not None and len(w) > 0:\n",
    "            waveforms.append(w)\n",
    "    if not waveforms:\n",
    "        continue\n",
    "    # Concatenate all coughs with 50ms gap\n",
    "    parts = []\n",
    "    gap = torch.zeros(GAP_SAMPLES)\n",
    "    for i, w in enumerate(waveforms):\n",
    "        parts.append(w)\n",
    "        if i < len(waveforms) - 1:\n",
    "            parts.append(gap)\n",
    "    combined = torch.cat(parts)\n",
    "    # Split into 3s segments\n",
    "    n_segments = max(1, len(combined) // SEGMENT_SAMPLES)\n",
    "    for i in range(n_segments):\n",
    "        start = i * SEGMENT_SAMPLES\n",
    "        end = start + SEGMENT_SAMPLES\n",
    "        seg = combined[start:end]\n",
    "        if len(seg) < SEGMENT_SAMPLES:\n",
    "            pad_total = SEGMENT_SAMPLES - len(seg)\n",
    "            pad_left = pad_total // 2\n",
    "            pad_right = pad_total - pad_left\n",
    "            seg = torch.nn.functional.pad(seg, (pad_left, pad_right))\n",
    "        all_segments.append(seg)\n",
    "        all_labels.append(label)\n",
    "        all_pids.append(pid)\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_pids = np.array(all_pids)\n",
    "counts = list(Counter(all_pids).values())\n",
    "\n",
    "print(f'\\nTotal segments: {len(all_segments)} @ 3s')\n",
    "print(f'Patients: {len(np.unique(all_pids))}')\n",
    "print(f'Seg/patient: mean={np.mean(counts):.1f}, min={min(counts)}, max={max(counts)}')\n",
    "print(f'1 segment only: {sum(1 for c in counts if c == 1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 3: Model + Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoughClassifier(nn.Module):\n",
    "    def __init__(self, model_name='facebook/wav2vec2-base', dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.wav2vec2 = Wav2Vec2Model.from_pretrained(model_name)\n",
    "        # Freeze feature extractor only, keep transformer trainable\n",
    "        self.wav2vec2.feature_extractor._freeze_parameters()\n",
    "        hidden = self.wav2vec2.config.hidden_size  # 768\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.wav2vec2(x).last_hidden_state  # (B, T, 768)\n",
    "        pooled = out.mean(dim=1)  # (B, 768)\n",
    "        return self.head(pooled).squeeze(-1)  # (B,)\n",
    "\n",
    "class CoughDataset(Dataset):\n",
    "    def __init__(self, segments, labels, pids):\n",
    "        self.segments = segments\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "        self.pids = pids\n",
    "    def __len__(self): return len(self.segments)\n",
    "    def __getitem__(self, idx):\n",
    "        return {'audio': self.segments[idx], 'label': self.labels[idx], 'pid': self.pids[idx]}\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "GRAD_ACCUM = 8\n",
    "LR = 3e-5\n",
    "EPOCHS = 5\n",
    "N_FOLDS = 10\n",
    "\n",
    "print(f'=== Trial 1 Config ===')\n",
    "print(f'Batch: {BATCH_SIZE} (effective: {BATCH_SIZE * GRAD_ACCUM})')\n",
    "print(f'LR: {LR}, Epochs: {EPOCHS}, Folds: {N_FOLDS}')\n",
    "print(f'Segment: {SEGMENT_SEC}s = {SEGMENT_SAMPLES} samples')\n",
    "\n",
    "m = CoughClassifier()\n",
    "n_total = sum(p.numel() for p in m.parameters())\n",
    "n_train = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "print(f'Total params: {n_total/1e6:.1f}M, Trainable: {n_train/1e6:.1f}M')\n",
    "del m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 4: Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = SEED + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)\n",
    "\n",
    "def train_one_fold(fold_num, train_segs, train_labs, train_pids,\n",
    "                   val_segs, val_labs, val_pids):\n",
    "    # Re-seed for each fold for reproducibility\n",
    "    torch.manual_seed(SEED + fold_num)\n",
    "    np.random.seed(SEED + fold_num)\n",
    "    random.seed(SEED + fold_num)\n",
    "    \n",
    "    train_ds = CoughDataset(train_segs, train_labs, train_pids)\n",
    "    val_ds = CoughDataset(val_segs, val_labs, val_pids)\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                              num_workers=0, worker_init_fn=seed_worker, generator=g)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    \n",
    "    model = CoughClassifier().to(DEVICE)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=LR, weight_decay=0.01\n",
    "    )\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    total_steps = (len(train_loader) * EPOCHS) // GRAD_ACCUM\n",
    "    warmup_steps = int(total_steps * 0.1)\n",
    "    scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "        optimizer, start_factor=0.1, total_iters=max(warmup_steps, 1)\n",
    "    )\n",
    "    \n",
    "    best_auroc = 0\n",
    "    best_patient_logits = {}\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        for step, batch in enumerate(train_loader):\n",
    "            audio = batch['audio'].to(DEVICE)\n",
    "            labels = batch['label'].to(DEVICE)\n",
    "            loss = criterion(model(audio), labels) / GRAD_ACCUM\n",
    "            loss.backward()\n",
    "            \n",
    "            if (step + 1) % GRAD_ACCUM == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "            train_loss += loss.item() * GRAD_ACCUM\n",
    "        \n",
    "        # Flush remaining gradients\n",
    "        if (step + 1) % GRAD_ACCUM != 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        seg_probs, seg_labels, seg_pids = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                audio = batch['audio'].to(DEVICE)\n",
    "                probs = torch.sigmoid(model(audio)).cpu().numpy()\n",
    "                seg_probs.extend(probs)\n",
    "                seg_labels.extend(batch['label'].numpy())\n",
    "                seg_pids.extend(batch['pid'])\n",
    "        \n",
    "        # Patient-level aggregation (soft voting)\n",
    "        pt_p, pt_l = {}, {}\n",
    "        for pid, prob, lab in zip(seg_pids, seg_probs, seg_labels):\n",
    "            pt_p.setdefault(pid, []).append(prob)\n",
    "            pt_l[pid] = lab\n",
    "        \n",
    "        yt = np.array([pt_l[p] for p in pt_p])\n",
    "        yp = np.array([np.mean(v) for v in pt_p.values()])\n",
    "        auroc = roc_auc_score(yt, yp) if len(np.unique(yt)) > 1 else 0.5\n",
    "        \n",
    "        improved = ' *' if auroc > best_auroc else ''\n",
    "        print(f'  Epoch {epoch+1}/{EPOCHS} \\u2014 loss: {train_loss:.4f}, AUROC: {auroc:.4f}{improved}')\n",
    "        \n",
    "        if auroc > best_auroc:\n",
    "            best_auroc = auroc\n",
    "            best_patient_logits = {pid: np.mean(v) for pid, v in pt_p.items()}\n",
    "            os.makedirs('checkpoints_t1', exist_ok=True)\n",
    "            torch.save(model.state_dict(), f'checkpoints_t1/wav2vec2_fold{fold_num}.pt')\n",
    "    \n",
    "    del model, optimizer\n",
    "    if DEVICE.type == 'mps': torch.mps.empty_cache()\n",
    "    elif DEVICE.type == 'cuda': torch.cuda.empty_cache()\n",
    "    \n",
    "    return best_auroc, best_patient_logits\n",
    "\n",
    "print('Training function ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 5: Run 10-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pids = np.unique(all_pids)\n",
    "pid_labels = np.array([all_labels[all_pids == pid][0] for pid in unique_pids])\n",
    "\n",
    "n_folds_actual = min(N_FOLDS, int(min(Counter(pid_labels).values()) * 0.8))\n",
    "skf = StratifiedKFold(n_splits=n_folds_actual, shuffle=True, random_state=SEED)\n",
    "\n",
    "fold_aurocs = []\n",
    "all_patient_logits = {}\n",
    "all_patient_labels = {}\n",
    "\n",
    "print(f'=== TRIAL 1: Wav2Vec2 Cough-Only Baseline ===')\n",
    "print(f'Model: Wav2Vec2-base (feature_extractor frozen)')\n",
    "print(f'Segments: {len(all_segments)} @ 3s')\n",
    "print(f'Patients: {len(unique_pids)}')\n",
    "print(f'Folds: {n_folds_actual}, Device: {DEVICE}')\n",
    "print(f'\\n--- Benchmarks ---')\n",
    "print(f'Zambia study (audio-only): 0.852')\n",
    "print(f'DREAM Challenge winner:    0.743')\n",
    "print(f'\\nStarting training...\\n')\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(unique_pids, pid_labels)):\n",
    "    print(f'=== Fold {fold+1}/{n_folds_actual} ===')\n",
    "    \n",
    "    train_pids_set = set(unique_pids[train_idx])\n",
    "    val_pids_set = set(unique_pids[val_idx])\n",
    "    \n",
    "    tr_s, tr_l, tr_p = [], [], []\n",
    "    va_s, va_l, va_p = [], [], []\n",
    "    \n",
    "    for seg, lab, pid in zip(all_segments, all_labels, all_pids):\n",
    "        if pid in train_pids_set:\n",
    "            tr_s.append(seg); tr_l.append(lab); tr_p.append(pid)\n",
    "        else:\n",
    "            va_s.append(seg); va_l.append(lab); va_p.append(pid)\n",
    "    \n",
    "    print(f'  Train: {len(tr_s)} segments ({len(train_pids_set)} patients)')\n",
    "    print(f'  Val:   {len(va_s)} segments ({len(val_pids_set)} patients)')\n",
    "    \n",
    "    auroc, patient_logits = train_one_fold(\n",
    "        fold+1, tr_s, tr_l, tr_p, va_s, va_l, va_p\n",
    "    )\n",
    "    \n",
    "    fold_aurocs.append(auroc)\n",
    "    all_patient_logits.update(patient_logits)\n",
    "    for pid in val_pids_set:\n",
    "        all_patient_labels[pid] = pid_labels[unique_pids == pid][0]\n",
    "    \n",
    "    print(f'  \\u2705 Fold {fold+1} best AUROC: {auroc:.4f}\\n')\n",
    "\n",
    "print('=' * 60)\n",
    "print(f'TRIAL 1 RESULT')\n",
    "print(f'Mean AUROC: {np.mean(fold_aurocs):.4f} +/- {np.std(fold_aurocs):.4f}')\n",
    "print(f'Per-fold: {[f\"{a:.3f}\" for a in fold_aurocs]}')\n",
    "print(f'\\nDREAM winner:  0.743')\n",
    "print(f'Zambia study:  0.852')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 6: ROC + Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pids_order = sorted(all_patient_logits.keys())\n",
    "y_true = np.array([all_patient_labels[p] for p in pids_order])\n",
    "y_prob = np.array([all_patient_logits[p] for p in pids_order])\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "auroc = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "plt.figure(figsize=(8, 7))\n",
    "plt.plot(fpr, tpr, 'r-', lw=2.5, label=f'Trial 1 ({auroc:.3f})')\n",
    "plt.plot([0,1],[0,1],'k--', alpha=0.2)\n",
    "plt.axhspan(0.90, 1.0, xmin=0, xmax=0.30, alpha=0.08, color='green', label='WHO TPP zone')\n",
    "plt.axhline(0.90, color='r', ls=':', alpha=0.3)\n",
    "plt.axvline(0.30, color='g', ls=':', alpha=0.3)\n",
    "plt.xlabel('FPR (1 - Specificity)', fontsize=12)\n",
    "plt.ylabel('TPR (Sensitivity)', fontsize=12)\n",
    "plt.title('RespiraHub Trial 1 \\u2014 Wav2Vec2 Baseline', fontsize=14)\n",
    "plt.legend(fontsize=11); plt.grid(alpha=0.15)\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_trial1.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f'\\n{\"Thresh\":>7} {\"Sens\":>7} {\"Spec\":>7} {\"PPV\":>7} {\"NPV\":>7}')\n",
    "print('-' * 40)\n",
    "best_t, best_j = 0.5, -1\n",
    "for t in np.arange(0.10, 0.90, 0.05):\n",
    "    pred = (y_prob >= t).astype(int)\n",
    "    tp = np.sum((pred == 1) & (y_true == 1))\n",
    "    tn = np.sum((pred == 0) & (y_true == 0))\n",
    "    fp = np.sum((pred == 1) & (y_true == 0))\n",
    "    fn = np.sum((pred == 0) & (y_true == 1))\n",
    "    sens = tp/(tp+fn) if (tp+fn) else 0\n",
    "    spec = tn/(tn+fp) if (tn+fp) else 0\n",
    "    ppv = tp/(tp+fp) if (tp+fp) else 0\n",
    "    npv = tn/(tn+fn) if (tn+fn) else 0\n",
    "    j = sens + spec - 1\n",
    "    if j > best_j: best_j, best_t = j, t\n",
    "    flag = ' \\u2705 WHO' if (sens >= 0.90 and spec >= 0.70) else ''\n",
    "    print(f'{t:>7.2f} {sens:>7.3f} {spec:>7.3f} {ppv:>7.3f} {npv:>7.3f}{flag}')\n",
    "print(f'\\nBest Youden threshold: {best_t:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 7: Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'participant': pids_order,\n",
    "    'true_label': y_true,\n",
    "    'predicted_prob': y_prob,\n",
    "})\n",
    "results_df.to_csv('patient_predictions_trial1.csv', index=False)\n",
    "\n",
    "summary = {\n",
    "    'trial': 1,\n",
    "    'approach': 'Wav2Vec2-base, feature_extractor frozen, concat+split 3s',\n",
    "    'n_participants': len(pids_order),\n",
    "    'n_segments': len(all_segments),\n",
    "    'segment_sec': SEGMENT_SEC,\n",
    "    'n_folds': n_folds_actual,\n",
    "    'auroc_mean': round(float(np.mean(fold_aurocs)), 4),\n",
    "    'auroc_std': round(float(np.std(fold_aurocs)), 4),\n",
    "    'auroc_per_fold': [round(float(a), 4) for a in fold_aurocs],\n",
    "    'best_threshold': round(float(best_t), 2),\n",
    "    'seed': SEED,\n",
    "    'device': str(DEVICE),\n",
    "}\n",
    "with open('training_summary_trial1.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print('Saved:')\n",
    "print('  patient_predictions_trial1.csv')\n",
    "print('  training_summary_trial1.json')\n",
    "print('  checkpoints_t1/wav2vec2_fold*.pt')\n",
    "print('  roc_trial1.png')\n",
    "print(f'\\nFinal AUROC: {np.mean(fold_aurocs):.4f} +/- {np.std(fold_aurocs):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
